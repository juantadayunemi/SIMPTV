"""
Tareas de Celery para procesamiento de video en segundo plano.
ðŸ”¥ VERSIÃ“N CON WEBSOCKETS + REDIS
"""

import os
import logging
from datetime import datetime, timedelta
from celery import shared_task
from django.conf import settings
from django.utils import timezone
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync
from sympy import true
import torch
import time
from scipy.spatial import distance

logger = logging.getLogger(__name__)


@shared_task(bind=True, max_retries=3)
def analyze_video_async(self, analysis_id, video_path):
    """
    ðŸ”¥ Analiza video con actualizaciones en tiempo real vÃ­a WebSocket
    """
    import cv2
    from ultralytics import YOLO
    from apps.traffic_app.models import TrafficAnalysis, Vehicle, VehicleFrame

    # Capa de canales para WebSocket - mensajerÃ­a con el frontend
    channel_layer = get_channel_layer()
    room_group_name = f"traffic_analysis_{analysis_id}"

    def send_ws(message_type, data):
        """Enviar mensaje WebSocket"""
        try:
            async_to_sync(channel_layer.group_send)(
                room_group_name,
                {"type": message_type, "data": data}
            )
        except Exception as e:
            #logger.warning(f"âš ï¸ Error WS: {e}")
            ...

    try:
        logger.info(f"ðŸ§  Iniciando anÃ¡lisis {analysis_id}")
 
        # Abrir video con openCV
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception(f"No se puede abrir el video: {video_path}")
        
        # Verificar disponibilidad de GPU
        if torch.cuda.is_available():
            print(f"GPU detectada: {torch.cuda.get_device_name(0)}")
            print(f"NÃºmero de GPUs: {torch.cuda.device_count()}")
            print(f"Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        else:
            print("âŒ GPU NO DETECTADA")

        # Obtener anÃ¡lisis
        try:
            analysis = TrafficAnalysis.objects.get(id=analysis_id)
            analysis.status = "PROCESSING"
            analysis.save(update_fields=["status"])
            
        except TrafficAnalysis.DoesNotExist:
            logger.error(f"âŒ AnÃ¡lisis {analysis_id} no encontrado")
            return {"error": "AnÃ¡lisis no encontrado"}


        # Notificar inicio
        send_ws("analysis_started", {
            "analysis_id": analysis_id,
            "status": "PROCESSING",
            "message": "Iniciando anÃ¡lisis...",
        })


        # Cargar modelo YOLO
        model_path = getattr(settings, "YOLO_MODEL_PATH", "yolov8n.pt")
        model = YOLO(model_path)
        logger.info(f"âœ… YOLO cargado: {model_path}")
        
        
         # ðŸ”¬ DIAGNÃ“STICO: Medir velocidad pura de GPU
        logger.info("ðŸ”¬ Prueba de velocidad GPU...")
        cap.set(cv2.CAP_PROP_POS_FRAMES, 100)  # Ir a frame 100
        ret, test_frame = cap.read()

        # Calentar GPU
        for i in range(3):
            _ = model.predict(test_frame, device=0, imgsz=384, verbose=False)
        torch.cuda.synchronize()

        # Medir 10 inferencias
        test_times = []
        for i in range(10):
            start = time.time()
            _ = model.predict(test_frame, device=0, imgsz=384, verbose=False)
            torch.cuda.synchronize()
            test_times.append((time.time() - start) * 1000)

        avg_time = sum(test_times) / len(test_times)
        logger.info(f"âš¡ Velocidad GPU pura: {avg_time:.1f}ms/frame")
        logger.info(f"âš¡ FPS teÃ³rico: {1000/avg_time:.1f}")

        # Resetear video
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        # ðŸ”¥ DIAGNÃ“STICO CRÃTICO
        logger.info(f"ðŸ”¥ CUDA disponible: {torch.cuda.is_available()}")
        logger.info(f"ðŸ”¥ Device actual: {model.device}")

        # â­ AGREGAR ESTAS LÃNEAS AQUÃ:
        if torch.cuda.is_available():
            model.to('cuda:0')  # ðŸŽ¯ MOVER MODELO A GPU
            logger.info(f"âœ… Modelo movido a GPU")
            logger.info(f"âœ… Device despuÃ©s: {next(model.model.parameters()).device}")
            torch.cuda.empty_cache()
        else:
            logger.warning("âš ï¸ GPU no disponible")

        if torch.cuda.is_available():
            logger.info(f"ðŸ”¥ GPU: {torch.cuda.get_device_name(0)}")
            logger.info(f"ðŸ”¥ CUDA version: {torch.version.cuda}")
        else:
            logger.warning(f"âš ï¸ USANDO CPU - ESTO ES MUY LENTO")


        send_ws("log_message", {
            "message": f"Modelo YOLO cargado: {model_path}",
            "level": "info",
        })
        
        
        # InformaciÃ³n del video
        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        logger.info(f"ðŸ“¹ Video: {total_frames} frames @ {fps}fps")

        send_ws("log_message", {
            "message": f"Video: {total_frames} frames @ {fps}fps ({width}x{height})",
            "level": "info",
        })

        # Optimizaciones para RTX 3050 (4GB VRAM)
        next_vehicle_id = 1
        active_tracks = {}  # {track_id: {'bbox': [x,y,w,h], 'type': str, 'frames_missing': int}}
        MAX_FRAMES_MISSING = 5  # MÃ¡ximo frames sin detectar antes de eliminar track
        IOU_THRESHOLD_TRACKING = 0.3  # IoU mÃ­nimo para asociar detecciÃ³n con track
        SKIP_FRAMES = 3          # Procesar cada 3 frames
        IMGSZ = 480            # ResoluciÃ³n de entrada [616x346 para 16:9, 608x352 para 16:9, 384x216 para pruebas rÃ¡pidas]
        CONF_THRESHOLD = 0.5     # Umbral de confianza
        IOU_THRESHOLD = 0.45     # IoU para NMS
        USE_HALF_PRECISION = False  # âœ… CAMBIAR DE OFF A False
        MIN_FRAMES_TO_SAVE = 10  # MÃ­nimo de frames para guardar vehÃ­culo
        
        
        def calculate_iou(box1, box2):
            """Calcular IoU entre dos bounding boxes [x, y, w, h]"""
            x1, y1, w1, h1 = box1
            x2, y2, w2, h2 = box2
            
            # Coordenadas de intersecciÃ³n
            xi1 = max(x1, x2)
            yi1 = max(y1, y2)
            xi2 = min(x1 + w1, x2 + w2)
            yi2 = min(y1 + h1, y2 + h2)
            
            # Ãrea de intersecciÃ³n
            inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
            
            # Ãreas individuales
            box1_area = w1 * h1
            box2_area = w2 * h2
            
            # IoU
            union_area = box1_area + box2_area - inter_area
            return inter_area / union_area if union_area > 0 else 0
        
        
      
        def assign_track_ids(detections, active_tracks):
            """Asignar IDs a detecciones usando tracking simple"""
            nonlocal next_vehicle_id  # âœ… AGREGAR ESTA LÃNEA AL INICIO
            
            assigned_detections = []
            used_track_ids = set()
            
            # Incrementar frames_missing para todos los tracks
            for track_id in active_tracks:
                active_tracks[track_id]['frames_missing'] += 1
            
            # Para cada detecciÃ³n, buscar el mejor track
            for det in detections:
                det_bbox = det['bbox']
                det_type = det['vehicle_type']
                best_track_id = None
                best_iou = IOU_THRESHOLD_TRACKING
                
                # Buscar track mÃ¡s cercano del mismo tipo
                for track_id, track in active_tracks.items():
                    if track_id in used_track_ids:
                        continue
                    if track['type'] != det_type:
                        continue
                        
                    iou = calculate_iou(det_bbox, track['bbox'])
                    if iou > best_iou:
                        best_iou = iou
                        best_track_id = track_id
                
                # Asignar track ID
                if best_track_id is not None:
                    # Actualizar track existente
                    active_tracks[best_track_id]['bbox'] = det_bbox
                    active_tracks[best_track_id]['frames_missing'] = 0
                    det['track_id'] = best_track_id
                    used_track_ids.add(best_track_id)
                else:
                    # Crear nuevo track
                    track_id = next_vehicle_id
                    next_vehicle_id += 1
                    active_tracks[track_id] = {
                        'bbox': det_bbox,
                        'type': det_type,
                        'frames_missing': 0
                    }
                    det['track_id'] = track_id
                
                assigned_detections.append(det)
            
            # Eliminar tracks perdidos
            tracks_to_remove = [
                tid for tid, track in active_tracks.items()
                if track['frames_missing'] > MAX_FRAMES_MISSING
            ]
            for tid in tracks_to_remove:
                del active_tracks[tid]
            
            return assigned_detections


        frame_count = 0
        last_progress = 0
        tracked_vehicles = {}

        # Procesar frames del video
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1

            # Saltar frames para optimizar procesamiento
            if frame_count % SKIP_FRAMES != 0:
                continue
            
            # ====================================================================
            # DETECCIÃ“N SIN TRACKING 
            # ====================================================================

            start_time = time.time()
            
            timestamp_seconds = frame_count / fps if fps > 0 else 0

            # DetecciÃ³n con YOLO
            results = model.predict(
                frame,
                conf=CONF_THRESHOLD,
                iou=IOU_THRESHOLD,
                classes=[2, 3, 5, 7],
                verbose=False,
                imgsz=IMGSZ,  # ResoluciÃ³n reducida
                device=0,
                half=False,
            )
            
            if torch.cuda.is_available():
                torch.cuda.synchronize()
                
            # Opcional: Limpiar cachÃ© de CUDA periÃ³dicamente
            if frame_count % 100 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            # âœ… CALCULAR TIEMPO
            yolo_time = (time.time() - start_time) * 1000  # en milisegundos
            
            # Reducir frecuencia:
            if frame_count % 90 == 0:  # Log cada 90 frames
                logger.info(f"â±ï¸ YOLO tardÃ³: {yolo_time:.1f}ms en frame {frame_count}")
                
                
                
            # ====================================================================
            # PASO 1: PROCESAR DETECCIONES DE YOLO
            # ====================================================================
            detections_raw = []

            if results[0].boxes is not None and len(results[0].boxes) > 0:
                for box in results[0].boxes:
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    class_names = {2: "car", 3: "motorcycle", 5: "bus", 7: "truck"}
                    vehicle_type = class_names.get(cls, "unknown")
                    
                    bbox = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]
                    
                    detections_raw.append({
                        "vehicle_type": vehicle_type,
                        "bbox": bbox,
                        "confidence": conf,
                        "x1": int(x1),
                        "y1": int(y1),
                        "x2": int(x2),
                        "y2": int(y2),
                    })
           
           
            # ====================================================================
            # PASO 2: APLICAR TRACKING MANUAL
            # ====================================================================
            detections_to_send = assign_track_ids(detections_raw, active_tracks)
               
               
            # ====================================================================
            # PASO 3: GUARDAR EN tracked_vehicles
            # ====================================================================
            for det in detections_to_send:
                track_id = det['track_id']
                vehicle_type = det['vehicle_type']
                conf = det['confidence']
                x1, y1 = det['x1'], det['y1']
                x2, y2 = det['x2'], det['y2']
                
                # Guardar en diccionario de vehÃ­culos rastreados
                if track_id not in tracked_vehicles:
                    tracked_vehicles[track_id] = {
                        "type": vehicle_type,
                        "first_frame": frame_count,
                        "last_frame": frame_count,
                        "count": 1,
                        "confidence_sum": conf,
                        "frames": [],
                    }
                    
                    # Notificar nuevo vehÃ­culo detectado
                    send_ws("vehicle_detected", {
                        "track_id": track_id,
                        "vehicle_type": vehicle_type,
                        "frame": frame_count,
                        "total_vehicles": len(tracked_vehicles),
                    })
                else:
                    # Actualizar informaciÃ³n del vehÃ­culo existente
                    tracked_vehicles[track_id]["last_frame"] = frame_count
                    tracked_vehicles[track_id]["count"] += 1
                    tracked_vehicles[track_id]["confidence_sum"] += conf
                
                # Guardar informaciÃ³n del frame actual
                tracked_vehicles[track_id]["frames"].append({
                    "frameNumber": frame_count,
                    "timestamp_seconds": timestamp_seconds,
                    "boundingBox": {
                        "x": x1,
                        "y": y1,
                        "width": x2 - x1,
                        "height": y2 - y1,
                    },
                    "confidence": conf,
                })


            # ====================================================================
            # PASO 4: ENVIAR DETECCIONES AL FRONTEND
            # ====================================================================
            if detections_to_send and frame_count % 3 == 0:
                send_ws("frame_processed", {
                    "frame_number": frame_count,
                    "timestamp": round(timestamp_seconds, 2),
                    "detections": detections_to_send,
                })
                
 
            # ====================================================================
            # PASO 5: ACTUALIZAR PROGRESO
            # ====================================================================
            # Actualizar progreso cada 5%
            progress = (frame_count / total_frames) * 100
            if progress - last_progress >= 5:
                last_progress = progress

                # Contar vehÃ­culos por tipo
                car_count = sum(1 for v in tracked_vehicles.values() if v["type"] == "car")
                truck_count = sum(1 for v in tracked_vehicles.values() if v["type"] == "truck")
                moto_count = sum(1 for v in tracked_vehicles.values() if v["type"] == "motorcycle")
                bus_count = sum(1 for v in tracked_vehicles.values() if v["type"] == "bus")

                # Actualizar base de datos
                analysis.processedFrames = frame_count
                analysis.totalVehicles = len(tracked_vehicles)
                analysis.carCount = car_count
                analysis.truckCount = truck_count
                analysis.motorcycleCount = moto_count
                analysis.busCount = bus_count
                analysis.save(update_fields=[
                    "processedFrames", "totalVehicles",
                    "carCount", "truckCount", "motorcycleCount", "busCount"
                ])

                logger.info(f"ðŸ“Š {progress:.1f}% - {len(tracked_vehicles)} vehÃ­culos")

                # Notificar progreso al frontend
                send_ws("progress_update", {
                    "progress": round(progress, 2),
                    "processed_frames": frame_count,
                    "total_frames": total_frames,
                    "vehicles_detected": len(tracked_vehicles),
                    "vehicle_breakdown": {
                        "car": car_count,
                        "truck": truck_count,
                        "motorcycle": moto_count,
                        "bus": bus_count,
                    }
                })
                
                
        # Liberar recursos del video
        cap.release()

        # Guardar vehÃ­culos en base de datos
        logger.info(f"ðŸ’¾ Guardando {len(tracked_vehicles)} vehÃ­culos en la base de datos...")
        send_ws("log_message", {
            "message": f"Guardando {len(tracked_vehicles)} vehÃ­culos en base de datos...",
            "level": "info",
        })

        video_start_time = analysis.startedAt
        saved_vehicles = 0

        for track_id, vdata in tracked_vehicles.items():
            # Solo guardar vehÃ­culos con suficientes frames
            if vdata["count"] < MIN_FRAMES_TO_SAVE:
                continue

            try:
                # Calcular confianza promedio
                avg_confidence = vdata["confidence_sum"] / vdata["count"]
                
                # Calcular timestamps
                first_frame_time = video_start_time + timedelta(seconds=vdata["frames"][0]["timestamp_seconds"])
                last_frame_time = video_start_time + timedelta(seconds=vdata["frames"][-1]["timestamp_seconds"])
                
                # Generar ID Ãºnico para el vehÃ­culo
                vehicle_id = f"vehicle_{analysis_id}_{track_id}_{int(timezone.now().timestamp() * 1000)}"

                # Crear registro de vehÃ­culo
                vehicle = Vehicle.objects.create(
                    id=vehicle_id,
                    trafficAnalysisId=analysis,
                    vehicleType=vdata["type"],
                    confidence=round(avg_confidence, 4),
                    firstDetectedAt=first_frame_time,
                    lastDetectedAt=last_frame_time,
                    trackingStatus="COMPLETED",
                    totalFrames=vdata["count"],
                    storedFrames=len(vdata["frames"]),
                    plateProcessingStatus="PENDING",
                )

                # Crear registros de frames
                frames_to_create = []
                for frame_data in vdata["frames"]:
                    frame_timestamp = video_start_time + timedelta(seconds=frame_data["timestamp_seconds"])
                    frames_to_create.append(VehicleFrame(
                        vehicleId=vehicle,
                        frameNumber=frame_data["frameNumber"],
                        timestamp=frame_timestamp,
                        boundingBoxX=frame_data["boundingBox"]["x"],
                        boundingBoxY=frame_data["boundingBox"]["y"],
                        boundingBoxWidth=frame_data["boundingBox"]["width"],
                        boundingBoxHeight=frame_data["boundingBox"]["height"],
                        confidence=round(frame_data["confidence"], 4),
                        frameQuality=1.0,
                        speed=0,
                        imagePath="",
                    ))

                # Guardar todos los frames de una vez
                VehicleFrame.objects.bulk_create(frames_to_create)
                saved_vehicles += 1

            except Exception as e:
                logger.error(f"âœ–ï¸ Error guardando vehÃ­culo {track_id}: {e}")

        # Finalizar anÃ¡lisis
        analysis.processedFrames = frame_count
        analysis.totalFrames = total_frames
        analysis.totalVehicles = saved_vehicles
        analysis.status = "COMPLETED"
        analysis.endedAt = timezone.now()
        analysis.save()

        processing_time = (analysis.endedAt - analysis.startedAt).total_seconds()
        logger.info(f"âœ… AnÃ¡lisis {analysis_id} COMPLETADO en {processing_time:.1f}s")

        # Notificar anÃ¡lisis completado
        send_ws("analysis_completed", {
            "analysis_id": analysis_id,
            "status": "COMPLETED",
            "total_vehicles": saved_vehicles,
            "processing_time": processing_time,
            "vehicle_breakdown": {
                "car": analysis.carCount,
                "truck": analysis.truckCount,
                "motorcycle": analysis.motorcycleCount,
                "bus": analysis.busCount,
            }
        })

        send_ws("processing_complete", {
            "analysis_id": analysis_id,
            "status": "COMPLETED",
            "total_vehicles": saved_vehicles,
            "processing_time": processing_time,
        })

        return {
            "status": "COMPLETED",
            "analysis_id": analysis_id,
            "total_vehicles": saved_vehicles,
            "processing_time": processing_time,
        }

    except Exception as e:
        logger.error(f"âœ–ï¸ Error en el anÃ¡lisis: {e}", exc_info=True)

        try:
            analysis = TrafficAnalysis.objects.get(id=analysis_id)
            analysis.status = "ERROR"
            analysis.endedAt = timezone.now()
            analysis.save(update_fields=["status", "endedAt"])

            send_ws("analysis_error", {
                "analysis_id": analysis_id,
                "error": str(e),
                "message": "Error durante el procesamiento del video",
            })

            send_ws("processing_error", {
                "analysis_id": analysis_id,
                "error": str(e),
            })

        except Exception as inner_e:
            logger.error(f"Error en manejo de excepciones: {inner_e}")

        # Reintentar la tarea si falla
        raise self.retry(exc=e, countdown=60 * (2**self.request.retries))


@shared_task
def cleanup_old_analyses(days: int = 30):
    """
    Limpia anÃ¡lisis antiguos y sus archivos asociados
    
    Args:
        days: NÃºmero de dÃ­as para considerar un anÃ¡lisis como antiguo
    """
    from apps.traffic_app.models import TrafficAnalysis

    cutoff_date = timezone.now() - timedelta(days=days)
    old_analyses = TrafficAnalysis.objects.filter(status="COMPLETED", endedAt__lt=cutoff_date)

    deleted_count = 0
    deleted_files = 0

    for analysis in old_analyses:
        try:
            # Eliminar archivo de video si existe
            if analysis.videoPath and os.path.exists(analysis.videoPath):
                os.remove(analysis.videoPath)
                deleted_files += 1

            # Eliminar imÃ¡genes de frames si existen
            if hasattr(analysis, "vehicles"):
                # Asumo que 'vehicles' es el related_name del ForeignKey de Vehicle a TrafficAnalysis
                for vehicle in analysis.vehicles.all():
                    # Asumo que 'frames' es el related_name del ForeignKey de VehicleFrame a Vehicle
                    for frame in vehicle.frames.all():
                        if frame.imagePath and os.path.exists(frame.imagePath):
                            os.remove(frame.imagePath)
                            deleted_files += 1
                    vehicle.delete() # Esto tambiÃ©n eliminarÃ¡ los VehicleFrame asociados por la cascada

            # Eliminar registro de anÃ¡lisis
            analysis.delete()
            deleted_count += 1

        except Exception as e:
            logger.error(f"Error limpiando anÃ¡lisis {analysis.id}: {str(e)}")

    logger.info(f"ðŸ§¹ Limpieza completada: {deleted_count} anÃ¡lisis eliminados, {deleted_files} archivos eliminados")
    return {"deleted_analyses": deleted_count, "deleted_files": deleted_files}