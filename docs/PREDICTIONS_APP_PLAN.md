# üîÆ Predictions App - Plan de Implementaci√≥n

## üìã Descripci√≥n General

**App:** `apps.predictions_app`

Sistema de predicci√≥n de tr√°fico con Machine Learning que analiza datos hist√≥ricos para pronosticar:
- üöó **Cantidad de veh√≠culos** por hora/d√≠a/semana
- üìä **Nivel de congesti√≥n** (LOW, MEDIUM, HIGH, CRITICAL)
- ‚ö†Ô∏è **Embotellamiento probable** (probabilidad de congesti√≥n)
- üïê **Horarios pico** para cada ubicaci√≥n
- üìà **Tendencias temporales** (patrones semanales, mensuales, anuales)

---

## üéØ Objetivos

1. **Recolectar datos hist√≥ricos** de `TrafficAnalysisEntity` autom√°ticamente
2. **Entrenar modelos** de ML (LSTM, ARIMA, Random Forest) con datos hist√≥ricos
3. **Generar predicciones** para 1h, 6h, 24h, 48h adelante
4. **Evaluar precisi√≥n** comparando predicciones vs. datos reales
5. **Servir predicciones** v√≠a API REST para visualizaci√≥n en frontend
6. **Alertas autom√°ticas** cuando se detecta probabilidad de embotellamiento

---

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SHARED/ENTITIES                          ‚îÇ
‚îÇ  predictionEntities.ts (con @db: annotations)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚Üì
         python manage.py generate_entities
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              APPS/ENTITIES/MODELS                           ‚îÇ
‚îÇ  prediction.py (modelos abstractos DLL)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚Üì herencia
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            APPS/PREDICTIONS_APP                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  models.py          - Modelos concretos (heredan de DLL)   ‚îÇ
‚îÇ  tasks.py           - Celery tasks para predicciones       ‚îÇ
‚îÇ  ml/                - L√≥gica de Machine Learning           ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ models/      - Implementaciones de modelos ML       ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ training.py  - Entrenamiento de modelos             ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ prediction.py- Generaci√≥n de predicciones           ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ evaluation.py- Evaluaci√≥n de precisi√≥n              ‚îÇ
‚îÇ  serializers.py     - DRF Serializers                      ‚îÇ
‚îÇ  views.py           - API ViewSets                         ‚îÇ
‚îÇ  urls.py            - URL routing                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Modelos de Datos (con @db: annotations)

### ‚úÖ Ya completado en `predictionEntities.ts`

Las siguientes entidades tienen todas sus anotaciones @db: completas:

1. **TrafficHistoricalDataEntity** - Datos hist√≥ricos agregados por hora
2. **LocationTrafficPatternEntity** - Patrones detectados (hourly, daily, weekly)
3. **PredictionModelEntity** - Modelos de ML entrenados
4. **ModelTrainingJobEntity** - Jobs de entrenamiento
5. **TrafficPredictionEntity** - Predicciones generadas
6. **BatchPredictionEntity** - Batches de predicciones
7. **PredictionAccuracyEntity** - M√©tricas de precisi√≥n
8. **RealTimePredictionEntity** - Predicciones en tiempo real (cach√©)
9. **WeatherDataEntity** - Datos clim√°ticos (factor externo)
10. **EventDataEntity** - Eventos especiales (factor externo)

---

## üîÑ Flujo de Trabajo

### 1. **Recolecci√≥n de Datos Hist√≥ricos**

**Celery Task:** `collect_historical_data_task()`

- Se ejecuta cada hora (Celery Beat)
- Lee `TrafficAnalysisEntity` completados en la √∫ltima hora
- Agrega datos por ubicaci√≥n/hora
- Guarda en `TrafficHistoricalDataEntity`

```python
# apps/predictions_app/tasks.py
@shared_task
def collect_historical_data_task():
    """
    Agrega datos de TrafficAnalysis completados
    en la √∫ltima hora y guarda en TrafficHistoricalData
    """
    from apps.traffic_app.models import TrafficAnalysis
    from .models import TrafficHistoricalData
    
    # Obtener an√°lisis completados en √∫ltima hora
    one_hour_ago = timezone.now() - timedelta(hours=1)
    analyses = TrafficAnalysis.objects.filter(
        status='COMPLETED',
        endedAt__gte=one_hour_ago
    )
    
    # Agrupar por ubicaci√≥n + hora
    for location in set(a.locationId for a in analyses):
        hour_data = analyses.filter(locationId=location)
        
        # Calcular agregados
        avg_speed = hour_data.aggregate(Avg('avgSpeed'))['avgSpeed__avg']
        total_vehicles = hour_data.aggregate(Sum('totalVehicleCount'))['totalVehicleCount__sum']
        
        # Guardar en hist√≥rico
        TrafficHistoricalData.objects.create(
            location=f"LOC-{location}",
            date=timezone.now(),
            hour=timezone.now().hour,
            dayOfWeek=timezone.now().weekday(),
            month=timezone.now().month,
            vehicleCount=total_vehicles or 0,
            avgSpeed=avg_speed or 0,
            densityLevel=calculate_density(total_vehicles),
            isHoliday=is_holiday_today(),
            isWeekend=timezone.now().weekday() >= 5
        )
```

---

### 2. **Detecci√≥n de Patrones**

**Celery Task:** `detect_traffic_patterns_task(location_id)`

- Se ejecuta diariamente (Celery Beat)
- Analiza datos hist√≥ricos de los √∫ltimos 30 d√≠as
- Detecta patrones horarios, diarios, semanales
- Guarda en `LocationTrafficPatternEntity`

```python
@shared_task
def detect_traffic_patterns_task(location_id):
    """
    Detecta patrones de tr√°fico para una ubicaci√≥n
    usando datos de los √∫ltimos 30 d√≠as
    """
    from .ml.training import PatternDetector
    from .models import TrafficHistoricalData, LocationTrafficPattern
    
    # Obtener datos hist√≥ricos
    thirty_days_ago = timezone.now() - timedelta(days=30)
    historical_data = TrafficHistoricalData.objects.filter(
        location=f"LOC-{location_id}",
        date__gte=thirty_days_ago
    ).order_by('date', 'hour')
    
    # Detectar patrones
    detector = PatternDetector()
    patterns = detector.detect_patterns(historical_data)
    
    # Guardar patrones detectados
    for pattern_type, pattern_data in patterns.items():
        LocationTrafficPattern.objects.update_or_create(
            location=f"LOC-{location_id}",
            patternType=pattern_type,
            defaults={
                'patternData': json.dumps(pattern_data),
                'confidence': pattern_data.get('confidence', 0.8),
                'validFrom': timezone.now(),
                'validTo': timezone.now() + timedelta(days=30)
            }
        )
```

---

### 3. **Entrenamiento de Modelos**

**Celery Task:** `train_prediction_model_task(location_id, model_type)`

- Se ejecuta semanalmente o bajo demanda
- Entrena modelos con datos hist√≥ricos (3-6 meses)
- Eval√∫a precisi√≥n con validaci√≥n cruzada
- Guarda modelo entrenado en `PredictionModelEntity`

```python
@shared_task
def train_prediction_model_task(location_id, model_type='lstm'):
    """
    Entrena un modelo de predicci√≥n para una ubicaci√≥n
    
    Args:
        location_id: ID de la ubicaci√≥n
        model_type: 'lstm', 'arima', 'random_forest'
    """
    from .ml.training import ModelTrainer
    from .models import PredictionModel, ModelTrainingJob
    
    # Crear job de entrenamiento
    job = ModelTrainingJob.objects.create(
        modelId=generate_cuid(),
        status='running',
        startTime=timezone.now()
    )
    
    try:
        # Obtener datos de entrenamiento (6 meses)
        six_months_ago = timezone.now() - timedelta(days=180)
        training_data = TrafficHistoricalData.objects.filter(
            location=f"LOC-{location_id}",
            date__gte=six_months_ago
        )
        
        # Entrenar modelo
        trainer = ModelTrainer(model_type=model_type)
        model, metrics = trainer.train(training_data)
        
        # Guardar modelo
        prediction_model = PredictionModel.objects.create(
            id=job.modelId,
            modelName=f"{model_type.upper()}-LOC{location_id}-{timezone.now().strftime('%Y%m')}",
            modelType=model_type,
            location=f"LOC-{location_id}",
            features=json.dumps(trainer.feature_names),
            hyperparameters=json.dumps(trainer.hyperparameters),
            trainingDataPeriod=f"{six_months_ago.date()}_{timezone.now().date()}",
            accuracy=metrics['accuracy'],
            mse=metrics['mse'],
            mae=metrics['mae'],
            r2Score=metrics['r2_score'],
            trainedAt=timezone.now()
        )
        
        # Actualizar job
        job.status = 'completed'
        job.endTime = timezone.now()
        job.dataPointsUsed = training_data.count()
        job.validationScore = metrics['validation_score']
        job.save()
        
    except Exception as e:
        job.status = 'failed'
        job.errorMessage = str(e)
        job.endTime = timezone.now()
        job.save()
        raise
```

---

### 4. **Generaci√≥n de Predicciones**

**Celery Task:** `generate_predictions_task(location_id, horizon_hours)`

- Se ejecuta cada hora (Celery Beat)
- Genera predicciones para 1h, 6h, 24h adelante
- Usa el modelo activo m√°s reciente
- Guarda en `TrafficPredictionEntity`

```python
@shared_task
def generate_predictions_task(location_id, horizon_hours=[1, 6, 24]):
    """
    Genera predicciones de tr√°fico para una ubicaci√≥n
    
    Args:
        location_id: ID de la ubicaci√≥n
        horizon_hours: Lista de horizontes (horas adelante)
    """
    from .ml.prediction import TrafficPredictor
    from .models import PredictionModel, TrafficPrediction
    
    # Obtener modelo activo m√°s reciente
    model = PredictionModel.objects.filter(
        location=f"LOC-{location_id}",
        isActive=True
    ).order_by('-trainedAt').first()
    
    if not model:
        logger.warning(f"No hay modelo activo para ubicaci√≥n {location_id}")
        return
    
    # Cargar predictor
    predictor = TrafficPredictor(model)
    
    # Generar predicciones para cada horizonte
    for hours_ahead in horizon_hours:
        prediction_datetime = timezone.now() + timedelta(hours=hours_ahead)
        
        # Predecir
        result = predictor.predict(prediction_datetime)
        
        # Guardar predicci√≥n
        TrafficPrediction.objects.create(
            id=generate_cuid(),
            modelId=model.id,
            location=f"LOC-{location_id}",
            predictionDate=prediction_datetime,
            predictionHour=prediction_datetime.hour,
            predictedVehicleCount=result['vehicle_count'],
            predictedAvgSpeed=result['avg_speed'],
            predictedDensityLevel=result['density_level'],
            confidence=result['confidence'],
            predictionHorizon=hours_ahead
        )
```

---

### 5. **Evaluaci√≥n de Precisi√≥n**

**Celery Task:** `evaluate_predictions_task(location_id)`

- Se ejecuta diariamente
- Compara predicciones pasadas con datos reales
- Calcula m√©tricas de error (MAE, MSE)
- Guarda en `PredictionAccuracyEntity`

```python
@shared_task
def evaluate_predictions_task(location_id):
    """
    Eval√∫a precisi√≥n de predicciones comparando con datos reales
    """
    from .models import TrafficPrediction, TrafficHistoricalData, PredictionAccuracy
    
    # Obtener predicciones de hace 24 horas que ahora tienen datos reales
    yesterday = timezone.now() - timedelta(days=1)
    predictions = TrafficPrediction.objects.filter(
        location=f"LOC-{location_id}",
        predictionDate__date=yesterday.date(),
        actualVehicleCount__isnull=True  # A√∫n no se han actualizado
    )
    
    for prediction in predictions:
        # Buscar dato real
        actual_data = TrafficHistoricalData.objects.filter(
            location=prediction.location,
            date__date=prediction.predictionDate.date(),
            hour=prediction.predictionHour
        ).first()
        
        if actual_data:
            # Actualizar predicci√≥n con dato real
            prediction.actualVehicleCount = actual_data.vehicleCount
            prediction.actualAvgSpeed = actual_data.avgSpeed
            prediction.actualDensityLevel = actual_data.densityLevel
            prediction.predictionError = abs(
                prediction.predictedVehicleCount - actual_data.vehicleCount
            )
            prediction.save()
    
    # Calcular m√©tricas agregadas del √∫ltimo mes
    one_month_ago = timezone.now() - timedelta(days=30)
    evaluated_predictions = TrafficPrediction.objects.filter(
        location=f"LOC-{location_id}",
        predictionDate__gte=one_month_ago,
        actualVehicleCount__isnull=False
    )
    
    if evaluated_predictions.exists():
        errors = [p.predictionError for p in evaluated_predictions if p.predictionError]
        
        PredictionAccuracy.objects.create(
            id=generate_cuid(),
            modelId=evaluated_predictions.first().modelId,
            location=f"LOC-{location_id}",
            evaluationPeriod=f"{one_month_ago.date()}_{timezone.now().date()}",
            predictionHorizon=24,  # Evaluar predicciones a 24h
            totalPredictions=evaluated_predictions.count(),
            correctPredictions=sum(1 for e in errors if e < 5),  # Error < 5 veh√≠culos
            accuracy=sum(1 for e in errors if e < 5) / len(errors),
            avgError=sum(errors) / len(errors),
            maxError=max(errors),
            minError=min(errors),
            evaluatedAt=timezone.now()
        )
```

---

## ü§ñ Implementaci√≥n de Modelos ML

### Estructura de `ml/` module

```
apps/predictions_app/ml/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.py       # LSTM (Long Short-Term Memory)
‚îÇ   ‚îú‚îÄ‚îÄ arima_model.py      # ARIMA (AutoRegressive Integrated Moving Average)
‚îÇ   ‚îî‚îÄ‚îÄ rf_model.py         # Random Forest
‚îú‚îÄ‚îÄ training.py             # ModelTrainer class
‚îú‚îÄ‚îÄ prediction.py           # TrafficPredictor class
‚îú‚îÄ‚îÄ evaluation.py           # ModelEvaluator class
‚îî‚îÄ‚îÄ utils.py                # Feature engineering, preprocessing
```

### Ejemplo: LSTM Model

```python
# apps/predictions_app/ml/models/lstm_model.py
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

class LSTMTrafficModel:
    def __init__(self, sequence_length=24, features=10):
        self.sequence_length = sequence_length
        self.features = features
        self.model = self._build_model()
    
    def _build_model(self):
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=(self.sequence_length, self.features)),
            Dropout(0.2),
            LSTM(32, return_sequences=False),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1)  # Predicci√≥n de vehicleCount
        ])
        
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def train(self, X_train, y_train, epochs=50, batch_size=32):
        history = self.model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.2,
            verbose=1
        )
        return history
    
    def predict(self, X):
        return self.model.predict(X)
    
    def save(self, path):
        self.model.save(path)
    
    @classmethod
    def load(cls, path):
        from tensorflow.keras.models import load_model
        instance = cls()
        instance.model = load_model(path)
        return instance
```

---

## üõ†Ô∏è API Endpoints

### Endpoints de Predicciones

```python
# apps/predictions_app/urls.py
from django.urls import path, include
from rest_framework.routers import DefaultRouter
from . import views

router = DefaultRouter()
router.register(r'predictions', views.TrafficPredictionViewSet)
router.register(r'models', views.PredictionModelViewSet)
router.register(r'historical', views.TrafficHistoricalDataViewSet)
router.register(r'accuracy', views.PredictionAccuracyViewSet)

urlpatterns = [
    path('', include(router.urls)),
    path('predict/<int:location_id>/', views.generate_prediction_view),
    path('train/<int:location_id>/', views.train_model_view),
]
```

### ViewSets

```python
# apps/predictions_app/views.py
from rest_framework import viewsets, status
from rest_framework.decorators import action
from rest_framework.response import Response
from .models import TrafficPrediction, PredictionModel
from .serializers import TrafficPredictionSerializer, PredictionModelSerializer

class TrafficPredictionViewSet(viewsets.ReadOnlyModelViewSet):
    queryset = TrafficPrediction.objects.all()
    serializer_class = TrafficPredictionSerializer
    
    @action(detail=False, methods=['get'])
    def by_location(self, request):
        """
        GET /api/predictions/predictions/by_location/?location=LOC-1&hours=24
        
        Retorna predicciones para una ubicaci√≥n en las pr√≥ximas N horas
        """
        location = request.query_params.get('location')
        hours_ahead = int(request.query_params.get('hours', 24))
        
        predictions = TrafficPrediction.objects.filter(
            location=location,
            predictionDate__gte=timezone.now(),
            predictionDate__lte=timezone.now() + timedelta(hours=hours_ahead)
        ).order_by('predictionDate')
        
        serializer = self.get_serializer(predictions, many=True)
        return Response(serializer.data)
    
    @action(detail=False, methods=['get'])
    def real_time(self, request):
        """
        GET /api/predictions/predictions/real_time/?location=LOC-1
        
        Retorna predicci√≥n en tiempo real (cach√©) con 1h, 6h, 24h adelante
        """
        location = request.query_params.get('location')
        
        prediction = RealTimePrediction.objects.filter(
            location=location
        ).order_by('-lastUpdated').first()
        
        if not prediction:
            return Response({'error': 'No predictions available'}, status=404)
        
        return Response({
            'location': prediction.location,
            'current': {
                'vehicleCount': prediction.currentVehicleCount,
                'densityLevel': prediction.currentDensityLevel
            },
            'predictions': {
                '1h': {
                    'vehicleCount': prediction.next1HourPrediction,
                    'confidence': prediction.confidence1Hour
                },
                '6h': {
                    'vehicleCount': prediction.next6HourPrediction,
                    'confidence': prediction.confidence6Hour
                },
                '24h': {
                    'vehicleCount': prediction.next24HourPrediction,
                    'confidence': prediction.confidence24Hour
                }
            },
            'lastUpdated': prediction.lastUpdated
        })

class PredictionModelViewSet(viewsets.ReadOnlyModelViewSet):
    queryset = PredictionModel.objects.filter(isActive=True)
    serializer_class = PredictionModelSerializer
    
    @action(detail=False, methods=['get'])
    def by_location(self, request):
        """
        GET /api/predictions/models/by_location/?location=LOC-1
        
        Retorna el modelo activo para una ubicaci√≥n
        """
        location = request.query_params.get('location')
        
        model = PredictionModel.objects.filter(
            location=location,
            isActive=True
        ).order_by('-trainedAt').first()
        
        if not model:
            return Response({'error': 'No model found'}, status=404)
        
        serializer = self.get_serializer(model)
        return Response(serializer.data)
```

---

## ‚è∞ Celery Beat Schedule

```python
# config/settings.py

from celery.schedules import crontab

CELERY_BEAT_SCHEDULE = {
    # Recolectar datos hist√≥ricos cada hora
    'collect-historical-data': {
        'task': 'apps.predictions_app.tasks.collect_historical_data_task',
        'schedule': crontab(minute=5),  # Cada hora a los 5 minutos
    },
    
    # Generar predicciones cada hora
    'generate-predictions': {
        'task': 'apps.predictions_app.tasks.generate_all_predictions',
        'schedule': crontab(minute=10),  # Cada hora a los 10 minutos
    },
    
    # Detectar patrones diariamente a las 2 AM
    'detect-patterns': {
        'task': 'apps.predictions_app.tasks.detect_all_patterns',
        'schedule': crontab(hour=2, minute=0),
    },
    
    # Evaluar precisi√≥n diariamente a las 3 AM
    'evaluate-predictions': {
        'task': 'apps.predictions_app.tasks.evaluate_all_predictions',
        'schedule': crontab(hour=3, minute=0),
    },
    
    # Re-entrenar modelos semanalmente (domingos a las 4 AM)
    'retrain-models': {
        'task': 'apps.predictions_app.tasks.retrain_all_models',
        'schedule': crontab(hour=4, minute=0, day_of_week=0),
    },
}
```

---

## üì¶ Dependencias Adicionales

```txt
# requirements.txt (agregar)

# Machine Learning
tensorflow==2.15.0           # LSTM models
scikit-learn==1.3.2          # Random Forest, preprocessing
statsmodels==0.14.1          # ARIMA models
pandas==2.1.4                # Data manipulation
numpy==1.26.2                # Numerical computing

# Feature Engineering
holidays==0.38               # Detecci√≥n de festivos
geopy==2.4.1                 # Geocoding (si necesario)

# Visualization (opcional, para debugging)
matplotlib==3.8.2
seaborn==0.13.0
```

---

## üöÄ Pasos de Implementaci√≥n

### Fase 1: Setup Inicial ‚úÖ
1. ‚úÖ Agregar anotaciones @db: a `predictionEntities.ts`
2. [ ] Ejecutar `python manage.py generate_entities`
3. [ ] Crear app: `python manage.py startapp predictions_app`
4. [ ] Agregar `"apps.predictions_app"` a `INSTALLED_APPS`
5. [ ] Crear modelos en `models.py` (heredar de DLL)
6. [ ] Ejecutar `python manage.py makemigrations predictions_app`
7. [ ] Ejecutar `python manage.py migrate`

### Fase 2: Recolecci√≥n de Datos ‚úÖ
1. [ ] Implementar `collect_historical_data_task()`
2. [ ] Configurar Celery Beat schedule
3. [ ] Probar recolecci√≥n manual con an√°lisis existentes

### Fase 3: Modelos ML ‚úÖ
1. [ ] Crear estructura `ml/` module
2. [ ] Implementar `LSTMTrafficModel`
3. [ ] Implementar `ARIMATrafficModel`
4. [ ] Implementar `RandomForestModel`
5. [ ] Crear `ModelTrainer` class
6. [ ] Crear `TrafficPredictor` class

### Fase 4: Entrenamiento ‚úÖ
1. [ ] Implementar `train_prediction_model_task()`
2. [ ] Implementar `detect_traffic_patterns_task()`
3. [ ] Probar entrenamiento con datos sint√©ticos
4. [ ] Entrenar primer modelo real

### Fase 5: Predicciones ‚úÖ
1. [ ] Implementar `generate_predictions_task()`
2. [ ] Implementar cach√© de `RealTimePrediction`
3. [ ] Probar generaci√≥n de predicciones

### Fase 6: API REST ‚úÖ
1. [ ] Crear serializers
2. [ ] Crear ViewSets
3. [ ] Configurar URLs
4. [ ] Documentar endpoints en Swagger

### Fase 7: Evaluaci√≥n y Ajuste ‚úÖ
1. [ ] Implementar `evaluate_predictions_task()`
2. [ ] Crear dashboard de m√©tricas
3. [ ] Ajustar hiperpar√°metros basado en resultados
4. [ ] Implementar re-entrenamiento autom√°tico

---

## üéØ Casos de Uso

### 1. **Dashboard de Predicciones (Frontend)**

Usuario ve:
- Predicci√≥n de veh√≠culos para pr√≥ximas 1h, 6h, 24h
- Gr√°fico de tendencia semanal
- Alerta si se predice embotellamiento
- Horarios pico recomendados para evitar

**Endpoint:**
```http
GET /api/predictions/predictions/by_location/?location=LOC-1&hours=24

Response:
{
  "predictions": [
    {
      "predictionDate": "2025-10-10T15:00:00Z",
      "predictionHour": 15,
      "predictedVehicleCount": 45,
      "predictedDensityLevel": "MEDIUM",
      "confidence": 0.87
    },
    ...
  ]
}
```

### 2. **Alertas de Embotellamiento**

Sistema env√≠a alerta si:
- Predicci√≥n de densityLevel = "CRITICAL" con confidence > 0.8
- En pr√≥ximas 2 horas

**Celery Task:**
```python
@shared_task
def send_congestion_alerts():
    predictions = TrafficPrediction.objects.filter(
        predictionDate__gte=timezone.now(),
        predictionDate__lte=timezone.now() + timedelta(hours=2),
        predictedDensityLevel='CRITICAL',
        confidence__gte=0.8
    )
    
    for prediction in predictions:
        # Enviar notificaci√≥n
        send_notification(
            title=f"‚ö†Ô∏è Embotellamiento Predicho",
            message=f"Se predice tr√°fico cr√≠tico en {prediction.location} a las {prediction.predictionHour}:00"
        )
```

### 3. **Re-entrenamiento Inteligente**

Si la precisi√≥n del modelo cae por debajo de 70% ‚Üí re-entrenar autom√°ticamente

```python
@shared_task
def check_model_accuracy_and_retrain():
    accuracies = PredictionAccuracy.objects.filter(
        evaluatedAt__gte=timezone.now() - timedelta(days=7)
    )
    
    for accuracy in accuracies:
        if accuracy.accuracy < 0.7:
            # Precisi√≥n muy baja, re-entrenar
            train_prediction_model_task.delay(
                location_id=extract_location_id(accuracy.location),
                model_type='lstm'
            )
```

---

## üìö Recursos y Referencias

- **LSTM for Time Series:** https://www.tensorflow.org/tutorials/structured_data/time_series
- **ARIMA in Python:** https://www.statsmodels.org/stable/examples/notebooks/generated/tsa_arma.html
- **Scikit-learn:** https://scikit-learn.org/stable/modules/ensemble.html#random-forests
- **Traffic Forecasting Papers:** 
  - "Deep Learning for Traffic Prediction" (2019)
  - "LSTM Networks for Traffic Flow Prediction" (2020)

---

‚úÖ **Plan de Predictions App Completo!**

üéØ **Pr√≥ximo paso:** Generar entidades y crear la app Django.

**Comando:**
```bash
cd backend
python manage.py generate_entities
python manage.py startapp predictions_app apps/predictions_app
```

¬øProcedo a generar las entidades? üöÄ
